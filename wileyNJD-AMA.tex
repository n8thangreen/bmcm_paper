\documentclass[AMA,STIX1COL]{WileyNJD-v2}
\usepackage{graphicx}
\usepackage{wrapfig}
% \usepackage{lscape}
\usepackage{pdflscape}
\usepackage{rotating}
\usepackage{epstopdf}
\usepackage{float}
\usepackage{subfig}
% \usepackage{endfloat}
\usepackage{bm,amssymb,amsmath}
\usepackage{trackchanges}  %http://trackchanges.sourceforge.net/help_stylefile.html

\addeditor{NGreen}
\addeditor{GBaio}

\articletype{Article Type}

\received{26 April 2016}
\revised{6 June 2016}
\accepted{6 June 2016}

\raggedbottom

\begin{document}

\title{Bayesian hierarchical mixture cure modelling \protect\thanks{title footnote.}}

\author[1]{Nathan Green*}

\author[4]{Murat Kurt}

\author[4]{Andriy Moshyk}

\author[2]{Victoria Federico Paly}

\author[1,3]{Gianluca Baio}

\authormark{N Green \textsc{et al}}

\address[1]{\orgdiv{Department of Statistical Science}, \orgname{UCL}, \orgaddress{\state{London}, \country{UK}}}

\address[2]{\orgdiv{Org Division}, \orgname{Org Name}, \orgaddress{\state{State name}, \country{Country name}}}

\address[3]{\orgdiv{Org Division}, \orgname{Org Name}, \orgaddress{\state{State name}, \country{Country name}}}

\address[4]{\orgdiv{Org Division}, \orgname{Bristol Myers Squibb}, \orgaddress{\state{State name}, \country{Country name}}}

\corres{*Nathan Green \email{n.green@ucl.ac.uk}}

\presentaddress{}

%ORCID ID: 0000-0002-7056-2741
\abstract[Summary]{
Time to an event of interest over a lifetime is a central measure of the clinical benefit of an intervention used in a health technology assessment (HTA).
Within the same trial multiple end-points may also be considered.
For example, overall and progression-free survival time for different drugs in oncology studies.
A common situation is when an intervention is only effective for some proportion of the population who are not clinically identifiable.
So we need to estimate latent group membership as well as separate survival models for each.
However, follow-up in trials may be relatively short leading to substantial censoring.
We present a general Bayesian hierarchical framework that can handle this complexity by exploiting the similarity of cure fractions between end-points;
accounting for the correlation between them and improving the extrapolation beyond the observed data.
Assuming exchangeability between cure fractions facilitates the borrowing of information between end-point.
We show the benefits of using our approach with a motivating example, the CheckMate 067 phase 3 trial.
}

\keywords{Bayesian, survival analysis, oncology}

\jnlcitation{\cname{%
\author{Green N.}, and
\author{G. Baio}} (\cyear{2021}), 
\ctitle{}, \cvol{2017;00:1--6}.}

\maketitle

\footnotetext{\textbf{Abbreviations:} MCM, mixture cure model}

\section{Introduction}\label{sec:intro}
%%% HTA perspective %%%
% survival data
Interventions that impact upon the time to an event of interest, such as disease progression or death in a cancer trial, form a high proportion of appraisals by Health Technology Assessment (HTA) agencies, such as the National Institute for Health and Care Excellence (NICE), in England \citep{Latimer2011}.
For instance, a new intervention may be expected to increase the amount of time until a patient experiences disease progression or death from any cause. For this reason, ``survival data'' are instrumental to modelling in HTA \cite{Demiris2006, Jackson2010}.

% what is a data-cut?
A feature of survival data from a trial is that they are often reported on during as well as at the end of the trial period.
This enables on-going assessments and can inform decisions such as an early end to the trial due to harm or futility.
However, in reality it is normally not possible to make use of the collected data in real time because there is a period in which they need to be cleaned due to issues, such as missingness and other data quality errors.
So, snapshots of the trial data are made at pre-specified points defined in the study protocol.
This can be at a particular date, follow-up time, or a particular number of patients.
These subsets of survival data made at discrete times are called \textit{data-cuts}.

% extrapolation
In order to quantify accurately the health and economic benefits of a new intervention using such survival data it is necessary to estimate the {\it mean survival time}, i.e.~the \textit{long term} effects of a given intervention.
This is in contrast to general survival curve summaries, such as the median time, which are typically used in standard ``biostatistical'' analyses.
This idiosyncrasy has important implications because, in order to calculate the mean survival time we require the full survival curve, i.e. over a patient's lifetime, but available data (e.g.~data-cuts from a randomised trial) almost inevitably only cover a limited time frame and are subject to a high degree of censoring.
Thus, it is necessary to \textit{extrapolate} the observed survival curve to a time horizon that is typically much longer than the one considered in the experimental study.
Consequently, unlike ``standard'' time-to-event analyses that are often based on semi-parametric models (e.g.~Cox regression), HTA modelling is based on a fully parametric approach to the survival analysis, as recommended by a highly influential NICE Decision Support Unit (DSU) Technical Support Document (TSD) \citep{Latimer2011}.

% plateaus
Another important feature of survival data in the field of cancer research has arisen in the past decade due to the development of potentially highly successful immuno-oncology treatments.
These aim to stimulate the body’s immune system to recognise and kill cancer cells \cite{Ouwens2019}. Several types of immunotherapy can be used to treat melanoma including immune checkpoint inhibitors, interleukin-2 (IL-2) and oncolytic virus therapy.
In particular, inhibitory immune checkpoint blockade combination therapies have shown significant success in promoting immune responses against cancer and can result in tumor regression in many patients \cite{Khair2019}.
These advances have lead to cancer patients with improved survival end-points and more long-term survival (LTS) patients comparable to the general population.
In previous immuno-oncologic studies for melanoma therapies, such as ipilimumab and nivolumab,
results have indicated that survival curves ``plateau'' for a considerable proportion of LTS patients in the limited range of the available survival curve \citep{Wolchok2017, Larkin2019}.
That is, the survival curve converges to a probability (substantially) greater than zero and does not appear to decrease further.
% mixture cure models
When a survival curve exhibits this plateau behaviour, it is common to adopt a \textit{mixture cure model} (MCM) approach to describe the generation of the underlying data.
A MCM considers a population as a mixture of two groups: the cured and not cured.
In our case, the cured group contains the LTS patients.
In many MCM analyses the survival associated with the uncured fraction of the population is represented by a Cox proportional hazard model.

% data-cut extrapolation 
However, the survival plateaus indicating a proportion of LTS may not have been reached at the time of a data-cut (including the planned end of the study).
In order to obtain complete survival curves to use in an HTA evaluation we need to extrapolate the survival curves to the sustained plateaus.
Ideally, these extrapolations should be consistent between data-cuts \citep{Bullement2020}.
The question of how to principally and usefully do this in situations where trials include multiple treatment arms and end-points is the subject of this paper.
The fact that we consider multiple end-points within a trial in the same analysis means that information about the plateau from data for one end-point can potentially help inform the estimation of the plateau for another end-point.
This can enable consistency between plateau estimates and maximise the utility of all available data.

% review of related work
Within a frequentist paradigm, an example of related work is a multi-level modelling approach in mixture cure modelling using random effects to model multilevel clustering structure in the linear predictors in both hazard function and cured probability parts \cite{Lai2009}.
Correlation between random effects in the uncured survival and cure fraction has been investigated using a bivariate Normal distribution \cite{Lai2008} \cite{Tan2018}.
Instead, we will impose dependency with hyperparameters.
% Tan2018 model log HR rather than cure fraction
To our knowledge there has been no Bayesian fully-parametric mixture cure model with a multi-level modelling structure for end-points.

% plan of the paper
The paper is structured as follows.
In the next section, the motivating example and data used throughout is outlined.
We introduce the basic mixture cure model in Section~\ref{section:basic_model}, before extending this to our Bayesian hierarchical model in Section~\ref{section:hier_model}.
In Section~\ref{sec:application} our novel modelling approach is applied to the motivating example dataset.
Comparisons are made between our approach and an independent model analogue.
Finally, in Section~\ref{sec:discussion} we discuss the results and future work.

%
\section{Motivating example}\label{sec:example}
Our motivating example concerns a long term study of melanoma therapies.
The study has been described in detail elsewhere so we give a brief overview of the data here (see \citep{Wolchok2017, Larkin2019, Hodi2018} for more details).
The \textit{CheckMate 067} trial is a phase 3 randomised, double-blind study conducted on eligible patients aged 18 years or older with previously untreated, unresectable stage III or IV melanoma.
They were randomly assigned in a 1:1:1 ratio and stratified by anti–programmed death-1 ligand 1 (PD-L1) antibodies status, whether there is a change in the BRAF gene that makes it work incorrectly (BRAF mutation), and metastasis stage.
The purpose of the trial was to test the effectiveness of ipilimumab, an anti–cytotoxic T-lymphocyte–associated antigen 4 monoclonal antibody, and nivolumab, an anti–programmed death 1 agent.
The total baseline sample consists of $n = 945$ subjects divided across three treatment arms
i) Ipilimumab monotherapy with regimen of 3 mg/kg IV once every 3 weeks (Q3W) for a total of 4 doses;
ii) Nivolumab monotherapy with regimen of 3 mg/kg intravenous (IV) once every 2 weeks (Q2W);
iii) Combined nivolumab with ipilimumab with regimen of 1 mg/kg IV and 3 mg/kg IV Q3W for 4 doses followed by nivolumab 3 mg/kg IV Q2W.
Nivolumab alone or nivolumab plus ipilimumab was compared with ipilimumab alone in patients with metastatic melanoma.
The co-primary end-points were \textit{progression-free survival} (PFS; i.e.~the time from randomisation until the first of disease progression or death) and \textit{overall survival} (OS; i.e.~the time from randomisation to time of death).
The data source for the analysis consists of patient-level data of times to PFS and OS with covariates sex, age at start of trial and nationality.

In our data set the minimum study follow-up from randomisation was 60 months so this was used as the final data-cut time.
We also considered two earlier artificial data-cuts by truncating the 60-month data at 12 and 30 months.
These particular times were chosen for this analysis because the actual study had a planned data-cut at approximately 30 months (28 months) and the largest observed median time for OS was just over 30 months. Thus, this time is relevant to the trial and at this time it may be possible to make comparable inferences to the complete 60-months data set but at a significantly earlier time.
Further, the latest median time between all treatment regimens for PFS was approximately 12 months. Therefore, at 12 months it may be possible to characterise the PFS survival curves but not the less mature OS and so borrowing information between PFS and OS may be advantageous. Taking a data-cut at an even earlier time would probably not provide sufficient information to enable any useful extrapolation. Primarily, the data-cut points were selected to demonstrate the theoretical justification of our method and not to strictly follow the study data-cut protocol.

Figure~\ref{fig:S_raw_data} shows the Kaplan-Meier estimates of the PFS and OS survival curves for the complete CheckMate 067 phase 3 trial data.
Summary statistics are presented in Table~\ref{tab:checkmate_summary}.
Both sets of curves for PFS and OS appear to tend toward positive asymptotes, the PFS curves more clearly.

%%TODO: should we remove table?
% There is a lot of information about CM067 trial results. It is helpful for the reader to get all info in one place. However, 5y DBL was published in Larkin et al. 2019 NEJM. We would have to compare every data point as it was presented in the clinical manuscript. An easier approach is to describe high level and point to the clinical manuscript.

\begin{center}
\begin{table*}[!ht]
\caption{Summary statistics of the CheckMate 067 phase 3 trial, for progression-free survival (PFS) and overall survival (OS). \label{tab:checkmate_summary}}
\centering
\begin{tabular}{r c c c c c c}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{PFS} & \multicolumn{1}{l}{} &\multicolumn{2}{c}{OS}\\
\cmidrule{2-3}\cmidrule{5-6}
 Treatment arm & Median time (months) & Events & & Median time (months) & Events & N\\
               & (95\% CI)            &        & & (95\% CI)            &        & \\
 \midrule
 Ipilimumab  & 2.86 (2.79-3.29)   & 261 & & 20.0 (17.22-25.6) & 228 & 311\\
 Nivolumab   & 6.93 (5.32-10.41)  & 203 & & 36.9 (31.24-60.9) & 175 & 313\\
 Combination & 11.50 (9.26-20.80) & 182 & & - & 151 & 313\\ 
\bottomrule
\end{tabular}
\end{table*}
\end{center}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.6\linewidth]{km_raw_data.png}
\caption{\label{fig:S_raw_data} Kaplan-Meier curves of PFS and OS times with 95\% CI for the complete CheckMate 067 phase 3 trial data and ipilimumab, nivolumab and combination treatments.}
\end{figure}

%
\section{Modelling framework}\label{sec:methods}
\note[GBaio]{I wonder whether you could simplify the notation in this section and remove the index j throughout?}
Consider a study in which $n$ individuals are observed and the (non-negative) time to either progression ($T^{prog}_{i}$) or death ($T^{death}_{i}$) are recorded for each individual $i=1,\ldots,n$.
Denote the event time for individual $i$ by $T_{i}$.
In our motivating example, we would have a separate set of $T_{i}$ for either end-point, PFS or OS.
Thus, PFS times are $T_{i} = \min(T^{prog}_{i}, T^{death}_{i})$ and OS times are $T_{i} = T^{death}_{i}$.
Event times may be censored and therefore we consider a censoring time $C_{i}$ and an event indicator $\delta_{i} = \mathbb{I}(T_{i} < C_{i})$
--- so that $\delta_{i} = 1$ if the end-point is fully observed for individual $i$ and 0 if it is censored.
The observed survival time is then indicated as $t_{i} = \min(T_{i}, C_{i})$.

Typically, a study will also measure some individual-level covariates, which we assume are collected in a vector $\bm{x}_{i} = (x_{1i}, \ldots, x_{Pi})^\top$.
These may include the individual's age, sex, comorbidities and, usually, a treatment arm indicator.
The full data can then be represented as
$\mathcal{D}_i = (t_i, \delta_i, \bm{x}_i)$.
% $\mathcal{D}_i = (\bm{t}_i, \bm{\delta}_i, \bm{x}_i)$.
% where $\bm{t}_i = (\bm{t}_{1i}, \bm{t}_{2i})$, $\bm{x}_i = (\bm{x}_{1i}, \bm{x}_{2i})$ and $\bm{\delta}_i = (\bm{\delta}_{1i}, \bm\delta_{2i})$.
In our example, the covariates are the same between PFS ans OS.

We model the observed times using a parametric sampling distribution $t_{i} \sim p(t_{i} \mid \bm\theta)$ as a function of a set of model parameters $\bm\theta = (\bm\alpha(\bm x), \mu(\bm x))$. 
In this notation, the location parameter $\mu(x)$ indicates the mean or the scale of the probability distribution; and a (set of) ancillary parameters $\bm \alpha(x)$ describe the shape or variance of the distribution.
Whilst it is possible for both $\mu$ and $\bm\alpha$ to explicitly depend on the covariates $\bm x$, usually the formulation is simplified to assume that these only affect directly the location parameter.
Since $t>0$, we typically use a generalised linear formulation.
So, for an individual $i$
$$
g(\mu) = \beta^{\mu}_{0} + \sum_{p=1}^P \beta^{\mu}_{p} x_{pi} \; [+ \ldots ],
$$
to model the rate or location parameter,
where $\beta^{\mu}_{0}$ represents an intercept,
and $\beta^{\mu}_{p}$ are the coefficients for an individual's measurements.
The $[+ \ldots]$ term indicates additional components for the linear predictor (e.g.~structured random effects).
The function $g(\cdot)$ is typically the logarithm.

\subsection{The standard mixture cure model} \label{section:basic_model}
Suppose that we observe a sustained plateau in the survival time data or have some other reason to believe that there is a long-term survivor group in our sample. We will now present the standard mixture cure model (sometimes called a long-term survival model) as the basis of the proposed model.
Denote the probability of being cured by the {\it cure fraction}, $\pi$.
The term "cure" here refers to the type of statistical model and does not literally mean that they are cured of disease. In our case, cured means that a patient has responded to treatment and is a LTS.
Because the cure models explicitly split patients in to two groups (cured or not) then the full set of model parameters consists of two separate groups.
Define $\bm\omega = (\bm\theta^b, \bm\theta^u)$, where superscript $b$ denotes the \textit{background} model and $u$ denotes the \textit{uncured} model.
In the standard cure model, cured individuals are usually assumed to have no chance of experiencing the event of interest in the period under consideration, simplifying the model.
There are several types of cure models and a rich and growing body of research in this area.
(see \citep{Yu2013} for a comparison and guidance with application to oncology.)

\note[GBaio]{I can understand \_b for "background", but why do we use \_u? Can we find a more straightforward notation?}
\note[NGreen]{this just seems to be what everyone else uses. "u"ncured perhaps?}

For an individual $i$ in a population with a cure fraction, the mixture cure model has the following survival model

\begin{equation}
\label{eqn:mcm}
S(t_{i} \mid \bm\omega, \bm{x}_i) = S_b(t_{i} \mid \bm\theta^b, \bm{x}_{i}) \left[\pi + (1 - \pi) S_u(t_{i} \mid \bm\theta^u, \bm{x}_{i}) \right],
\end{equation}
\\
\noindent
where $S(t) = 1 \!-\! \int_0^t p(s \mid \theta)\, \text{d}s$ denotes survival at time $t$,
$S_b(t \mid \bm\theta^b, \bm{x})$ is a function of the background mortality at time $t$ conditional on covariates $\bm{x}$,
% some papers denote \pi as _uncured_ fraction
and $S_u(t \mid \bm\theta^u, \bm{x})$ is a function of the (excess) mortality due to cancer at time $t$, conditional on covariates $\bm{x}$.
The formulation in equation~(\ref{eqn:mcm}) can be thought of as comprising of two submodels: i) an \textit{incidence} model for the cure fraction $\pi$. The general term from epidemiology is the rate or probability of a disease; ii) a \textit{latency} model for the survival function of the uncured population $S_u$. This is 'hidden' since it cannot be directly observed from the data.

The model above can be extended to account for multiple treatments, $K$; for instance, in our running example, $K=3$ and we could specify the cure fraction for treatment $k=1,\ldots,K$ using the following ``fixed'' effect model
\begin{equation}
\label{eqn:pi_regn}
\mbox{logit}(\pi_{k}) = \beta^{\pi}_{k} \; [+ \ldots],
\end{equation}
\noindent
where $\beta^{\pi}_k$ are the regression coefficients quantifying the impact of treatment $k$.
The $[+ \ldots]$ term could include a frailty term in the model.
The treatment index for an individual is included in the covariate vector $\bm{x}$ so that $\pi$ is replaced by $\pi(\bm{x})$ in equation~(\ref{eqn:mcm}).
% We will assume without loss of generalisability that all individuals have all treatments.
Note that although we are including all treatments arms in the same model we are not assuming any relationship between them. In particular, we do not suppose proportional hazards. This allows greater flexibility for the cases when proportional hazards is violated.

\subsubsection{Issues modelling multiple end-points in an HTA context} \label{section:issues}
There are several potential issues with existing approaches to cure modelling applied to an HTA context in particular.

% correlated events
Firstly, when the end-points are correlated, such as with the common events of interest overall survival (OS) and progression-free survival (PFS), this ought to be accounted for in the modelling.
There may be information in one sample of event times which we can use to improve the inference from another.
Performing separate, independent analyses may even give counter-intuitive results.
In the case of multiple types of end-points in the same trial, since the clinical interpretation of a cure fraction is the proportion of patients that are LTS,
it may make intuitive sense that there is a single underlying cure fraction.
For example, what would be the interpretation if there are differences in emergent survival plateaus between PFS and OS?
This is a clinically unintuitive dichotomy between the resulting proportions of long-term survivors.

% censoring
Secondly, time to event data are typically right-censored due to administrative censoring or loss to follow up.
The censoring times may be too early in order to adequately characterise a survival model for HTA for a single end-point.
In particular, OS times are bounded below by PFS times by definition so will be subject to more censoring at the same cut-point.
By taking advantage of the set of end-points together the data paucity may be alleviated to give better fits and extrapolation to the full lifetimes of patients.
This is particularly important for health economics modelling in order to gauge the full cost and effect of an intervention.

% our innovative proposal
We will now present a Bayesian hierarchical mixture cure model for multiple end-points.
This has the double advantage of borrowing information between end-points
(e.g. in the case of OS and PFS, the likely more mature PFS data can inform the often highly censored OS analysis) and obtaining a single cure fraction estimate.

%
\subsection{The hierarchical mixture cure model} \label{section:hier_model}
In this section, we show how to construct the extended mixture cure model in order to model multiple end-points together and alleviate the issues posed in the Section \ref{section:issues}.
In order to do this we must first introduce an additional index to denote an end-point $j = 1, \ldots, J$ --- typically, $J=2$ for PFS and OS.
We can now define a separate mixture cure model, as described in equation~(\ref{eqn:mcm}), for each of the end-points $j$.
With this in mind, let us consider three alternative multiple end-point incidence models for the estimation of the cure fraction for treatment $k$ and end-point $j$, denoted $\pi_{kj}$.

Firstly, the approach taken so far, and presented in Section \ref{section:basic_model}, is to model the cure fraction corresponding to each end-point completely separately (no pooling), assuming that they are independent.
$$
\pi_{kj} \perp\!\!\!\perp \pi_{kj'}, \; j,j' = 1, \ldots, J.
%\text{logit}(\pi_k) \sim \text{N}(\mu_k, \sigma_k^2), \; k = 1, \ldots, K.
$$
Secondly, we can assume that the cure fraction is the same for all end-points and so pool the samples (complete pooling).
In our example, PFS can be used as a proxy for OS since there are fewer missing data.
There may be no reason why the cure fraction should be different between different end-points, especially if individuals are observed for long enough.
In this case
$$
\pi_{kj} = \pi_{kj'}, \; j,j' = 1, \ldots, J.
$$
A potential issue with the complete pooling approach is that it ignores any variation in cure fraction that exists between end-points.

Lastly, and the approach proposed in this paper, is a compromise between the first two approaches called partial-pooling.
We propose a hierarchical structure on the cure fraction assuming exchangeability between all end-points $j$ for each treatment $k$.
We assume that there is a single, shared "common" cure fraction from which the separate end-point specific cure fractions are obtained, corresponding to equation~(\ref{eqn:pi_regn})
but where $\pi_{k}, \beta^{\pi}_{k}$ are no longer for particular end-points as before but now represent "global" values.
Using the global cure fraction we can define the second-level end-point specific cure fractions to be normally distributed as
$$
\text{logit}(\pi_{kj}) \sim \text{N}(\text{logit}(\pi_k), \sigma_k^2), \; j = 1, \ldots, J.  
$$
where $\sigma_k^2$ is the between-group (end-points) variance.
The end-point specific cure fractions in our example are denoted $\pi_{PFS}, \pi_{OS}$.
Figure~\ref{fig:hier_dag} shows a directed acyclic graphical (DAG) representation of the Bayesian hierarchical mixture cure modelling framework for two end-points.
The equivalent DAGs for the complete and no pooling models are given in the Appendix.
Note that pooling refers to the cure fractions. The survival times are not pooled; the parameters for the uncured survival models ($\phi$, $\beta^{\lambda}$ in the latency model) are estimated using the separate sets of survival times for each end-point.
E.g. in the complete pooling case we're not assuming that PFS and OS have the same survival time distributions.
However, in the complete and partial pooling case there is an indirect pooling effect for the latency models via the incidence model, so the fact that the cure fractions are similar/the same will influence the shapes of the survival curves.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.6\linewidth]{DAG_with_Tx.png}
\caption{\label{fig:hier_dag} A hierarchical mixture cure model DAG for a trial with two end-points. The trial indices correspond to the motivating example end-points of PFS (1) and OS (2).
Solid lines represent stochastic and dashed lines deterministic relationships, respectively.
Cured patients have fixed hazards e.g. taken from life tables.
The distribution of times for uncured patient regresses on covariates for the rate parameter and $\phi$ is the set of ancillary parameters.}
\end{figure}

%
\section{Application}\label{sec:application}
In this section we apply the models from Section~\ref{section:hier_model} to the CheckMate 067 dataset.
We first detail the modelling aspects specific to this analysis before presenting the results.

% software
This analysis was carried-out using the Stan inference engine \cite{carpenter2017stan} called from R \cite{Rcoreteam} using the package \texttt{rstan} on a Windows 10 PC.
Each fit employed 4 chains of 1000 iterations each, and a burn-in of 100 iterations.
The details of the algorithm can be found in the Appendix.
The packaged code is in a generalisable framework and can be downloaded from here.

%
\subsection{Background survival}
In many cure fraction models it is common to have $S_b(t, x) = 1$ for all $t$ under consideration, which is reasonable in the short-term.
However, we are focused on the full life-course of an individual in an HTA context and so include a general population all-cause mortality competing risk.
Thus, the uncured population is subject to a background mortality risk in addition to the risk from the event of interest.

We used the World Health Organisation (WHO) life tables by country for the latest year available of 2016 \cite{wholifetables} to inform the background mortality in the mixture cure model.
The baseline hazards are the expected mortality rate for each patient at the age at which they experience the event.
The mortality data are country, age and gender adjusted, thus providing a granular account of the different patient profiles in the trial.
The WHO reports conditional probabilities of death in 5-year intervals until age 85.
A constant annual mortality rate is reported for individuals over 85. They assumed that no-one lives beyond 100 years.
Further details are provided in the supplementary material.

In a Bayesian analysis there are alternative ways in which we could model the background mortality.
For this work we used WHO hazard point estimates as fixed and known.
We could consider the WHO estimates to provide sufficiently accurate estimates given the sample size and so incorporating uncertainty is not necessary. This also forces consistency across fits.
Denote the fixed WHO estimates for individual $i$ used for the background survival in (\ref{eqn:mcm}) as
$S_b(t_i \mid \bm\theta_b, \bm{x}_i) = \hat{S}_i$.

% background adjustment
It may be that the patients in the trial have a worse background survival than the average equivalent individual in the general population and so naively using the WHO life tables will over-estimate their survival times.
There are several possible ways that this could be addressed.
For example, using only the complete responders in the sample, who are clinically confirmed as cured, it is possible to obtain a posterior distribution for a hazard ratio between these and a WHO estimate baseline.
This can serve as a prior in the main model in a two-step approach. Alternatively, prior belief could be defined explicitly using expert knowledge.
This could be elicited directly for the hazard ratio or on a natural scale, such as mean lifetime, and transformed.

%
\subsection{Prior specification}
Where possible the choice of priors should be informed by expert opinion and prior results.
We specify vague priors on log-scale for the coefficients of the OS and PFS rates $\log(\lambda_{OS}),  \log(\lambda_{PFS})$.
Centering the ages, the baseline is a vague prior ${\beta_0^{PFS} \sim \text{N}(0, 100),}\; {\beta_0^{OS} \sim \text{N}(0, 100)}$
and for age $\beta_{age}^{PFS} \sim \text{N}(0, 100),\; \beta_{age}^{OS} \sim \text{N}(0, 100)$.
Alternatively, we could specify the cure fraction directly using a a Beta prior distribution $\pi \sim \text{Beta}(a, b)$.
The parameters can be obtained via transformation of the mean and standard deviation to allow a more natural scale for elicitation.

The hierarchical cure fraction is modelled as a fixed effect linear regression with logistic link. Each treatment coefficient prior is independent $\beta^{\pi}_k \sim \text{N}(-0.1, 0.2)$.
This corresponds to a prior mean cure fraction of just under 0.5, and approximately 10\% and 1\% chance of exceeding 0.6 and 0.7 respectively.
Prior predictive plots and further discussion are provided in the supplementary material.

The random effect variance on the global cure fraction is a noninformative (folded) half-Normal \cite{Gelman2006} with 
${\sigma^2 \sim \text{N}(0, 2.5)\mathbb{I}(0,)}$, where $\mathbb{I}(0,)$ denotes a distribution truncated at mean 0.
Alternatively, a noninformative uniform prior density on standard deviation parameters $\sigma$ is expected to generally work well when $J > 5$.
For small hierarchical variance a $\text{Gamma}(2, 0.1)$ may be preferred \cite{Chung2013}.

%
\subsection{Choice of survival distributions}
The hierarchical and separate models were fit for Exponential, Weibull, Gompertz, Log-Normal, Log-Logistic to the OS and PFS event times.
% which distributions
These are distributions from a suite of distributions given in NICE guidelines for Health Technology Assessments (HTA) \cite{Latimer2011}.
In general, providing this list has been interpreted by many in the HTA literature as meaning all of these distributions should be modelled with a given data set.
This prescriptive approach does not take into account what may be known {\it a priori} about the problem.
In reality, a subset of these parametric models will be more plausible for the data and so these are the ones that should be investigated.

%
\subsection{Model assessment}
We evaluated the goodness of fit of the overall models using out-of-sample predictions estimated with the widely applicable information criterion (WAIC) and leave-one-out cross-validation (LOO) \cite{Vehtari2017}.
These have various advantages to more common AIC and DIC and are easily obtained using the posterior sample of the Stan output.\\
% The effective number of parameters is not uniquely defined because it depends on the level of the hierarchy that is in {it focus} \cite{spiegelhalter}.
The set of parameters in the hierarchical model (and their dimensions) are
$\mathbf{\beta^{\pi}}$ (3), $\mathbf{\sigma}$ (3), $\mathbf{\beta^{\lambda}_{PFS}}$ (2), $\mathbf{\beta^{\lambda}_{OS}}$ (2), $\mathbf{\phi_{OS}}$ (1), $\mathbf{\phi_{PFS}}$ (1), $\mathbf{\pi_{OS}}$ (3), $\mathbf{\pi_{PFS}}$ (3).
Depending on the number of ancillary parameters the total is 16, 17 or 18.

% {\it We also calculated the 
% $\Delta S$ at months $t = 10, 20, 30, ...$\\
% clinical significant vs statistical significant differences.
% hazard ratio?\\
% median/mean survival?}\\

%%TODO: include this?
%% CrI widths
% In order to investigate potential decrease in the degree of uncertainty of the estimates as a result of borrowing of information across end-points, we calculated ratios of the width of the 95\% CrIs.
% Define as the ratio of the widths of the CrIs of $\pi_{os}$ and $\pi_{pfs}$ from the hierarchical model to the width of the CrIs of the separate model.

There has not been much work carried-out to date on model assessment methods specific to mixture cure models.
For the basic mixture cure model assessment may focus on the model as a whole or on the incidence and latency submodels separately.
The fit of the latency submodel can be examined using a revised Schoenfeld residual \cite{Wileyto2013} and the performance of the incidence submodel can be checked with concordance measures such as AUC \cite{Peng2021}.
However, these incidence model approaches are best used directly with known cure status and are designed for models which consider individual cure fractions, unlike our model which assumed a single population cure fraction.
Of course, we also extend the basic mixture cure model so it is not yet clear how to best use these methods in this situation. 
\note[NGreen]{are we interested in PH between treatments? [Tori] PH has been shown to be violated for these treatments for both endpoints (BMS should be able to provide references for that)}

%
\subsection{Complete data only results} \label{sec:results}
In this section, we will explore the mixture cure model fits using the complete 60-months CheckMate 067 trial data.
A selection of the hierarchical model posterior survival curves using the complete data are shown in Figure~\ref{fig:S_exp_lnorm_cf_hier}.
The equivalent plots for the separate models are given in the Appendix.

These figures show output for two models, with uncured fraction of either exponential or log-Normal for both OS and PFS.
The background survival is linearly decreasing with time and the same between plots, as expected using point estimates from WHO life tables.
Visual inspection of the fits demonstrate that both models perform reasonably well.
The PFS Kaplan-Meier curves show an initial steep decrease before levelling off.
The log-Normal distribution captures this early behaviour better but the exponential performs better at later times.
The OS Kaplan-Meier curves show a shallower curve and so are more closely fit by the exponential.
The survival curves for the uncured patients decrease more sharply for the log-Normal model.
% medians
For the exponential model, the PFS median times are 5, 9 and 12 months,
and for log-Normal model the PFS median times are 4, 6, 8 months, for ipilimumab, nivolumab and combined, respectively
Similarly, for the exponential model, the OS median times are 22, 38 and 56 months,
and for the log-Normal model the OS median times are 17, 29 and over 60 months, for ipilimumab, nivolumab and combined, respectively.
The uncured median survival times for the exponential model are 5 and 15 months, and for the log-Normal model 4 and 12 months, for PFS and OS, respectively.

%% restricted mean survival times
The restricted mean survival times at 60 months (RMST) are greater for the exponential models.
The RMST for the cured population is exactly value corresponding to the general population of 58.2 months.
For the exponential model the RMST (95\% credible interval, CrI) for the uncured group is 20.6 (18.4, 23.1) and 6.66 (6.09, 7.39) months, for OS and PFS, respectively. 
For the OS end-point the RMST is 28.7 (26.3, 31.1), 36.5 (34.1, 38.9) and 39.6 (37.1, 42.1) months, for ipilimumab, nivolumab and combined, respectively.
For the PFS end-point the RMST is 11.9 (9.96, 14.1), 24.3 (21.1, 27.4) and 27.7 (24.7, 30.8) months, for ipilimumab, nivolumab and combined, respectively.
For the the log-Normal model the RMST for the uncured group is 14.8 (13.6, 16.0) and 4.38 (4.16, 4.63) months, for OS and PFS, respectively. 
For the OS end-point the RMST is 27.3 (24.7, 29.9), 35.6 (32.9, 38.4) and 38.8 (36.4, 41.2) months, for ipilimumab, nivolumab and combined, respectively.
For the PFS end-point the RMST is 12.2 (9.85, 14.8), 27.2 (24.0, 30.2) and 30.5 (27.2, 33.7) months, for ipilimumab, nivolumab and combined, respectively.

% time to reach 0
The latest time PFS has survival probability greater than 0 is over 30 months for exponential and is below 15 months for log-Normal.
Similarly, the OS survival probability is greater than 0 at the end of follow-up at 60 months but reaches 0 for the log-Normal model at approximately 60 months.
The survival plots for the complete set of distributions are given in the supplementary Appendix.

%%TODO: include a table of survival statistics?
%%      compare curves formally? e.g. ANOVA, t-test RMST or HR?

\begin{figure}[!ht]
\centering
% produced using paper_output_plots.R
\includegraphics[width=0.7\linewidth]{plot_S_exp_lognormal_grid_cf_hier.png}
\caption{\label{fig:S_exp_lnorm_cf_hier} Hierarchical mixture cure model posterior survival curves for uncured fraction assumed (I) exponential; and (II) log-Normal for both OS and PFS, and ipilimumab, nivolumab and combination treatments. The black lines show the Kaplan-Meier curves using the complete CheckMate 067 trial data.}
\end{figure}

% cure fractions
Figure~\ref{fig:cf_forest_all_tx} and Figure~\ref{fig:cf_forest_all_tx_sep} show cure fraction posterior distribution forest plots for the hierarchical and separate mixture cure models, respectively. 
% global cf
We can see that the global cure fraction posterior is relatively wide which is understandable since there are only two exchangeable points providing limited information (OS and PFS).
They approximately range 0.1-0.55, 0.2-0.6, 0.2-0.65 for ipilimumab, nivolumab and combined treatments respectively. 
However, despite this, the data influence the end-point cure fractions by pulling the central location away from the prior, downwards for ipilimumab and upwards for the combined treatment.
For ipilimumab the PFS curve fraction posterior is close to containing zero within the credible interval.
Whereas for nivolumab and the combined treatment arms the mean global cure fraction lies somewhere between the PFS and OS means, the ipilimumab global mean is closer to the OS cure fraction mean. This is because we have explicitly codified in the prior distribution that the global cure fraction is unlikely to be near zero and the PFS cure fraction posterior is close to zero.
We would observe the equivalent behaviour if the OS distributions were near to 1.
% plateau time
The survival curves for the whole sample plateau to the background mortality survival from when the uncured survival probability reaches zero.
Since the background is user-supplied, in this case from the WHO life tables, then there is no additional insight from this time on-wards.
The times at which this occurs are relatively early for PFS and the log-Normal distribution.
% hier vs separate
Comparing the hierarchical and separate models there is not a noticeable difference between the two.
As mentioned above, there is limited information with only two end-points and a fairly weak prior.
There is a small amount of shrinkage such that the posterior distributions for OS and PFS are pulled toward the global mean, so that the PFS cure fractions are larger and the OS cure fractions are smaller in the hierarchical model than the separate model.


\begin{table*}[!ht]
\centering
\caption{WAIC statistics for hierarchical model and all distributions. \label{tab:waic_hier}}
\begin{tabular}{l|l|l|l|l}
\hline
\textbf{OS distn} & \textbf{PFS distn} & \textbf{ELPD\textsuperscript{$\dagger$}} & \textbf{$p_D^{\ddagger}$} & \textbf{WAIC} \\
\hline
exp & exp & -5064.82 (80.38) & 11.16 (0.46) & 10129.63 (160.77)\\
\hline
 & gompertz & -5065.64 (80.44) & 11.8 (0.49) & 10131.29 (160.88)\\
\hline
 & loglogistic & -4970.34 (80.72) & 11.78 (0.33) & 9940.68 (161.45)\\
\hline
 & lognormal & -4730.47 (92.79) & 18.04 (0.91) & 9460.94 (185.59)\\
\hline
 & weibull & -5062.99 (81.69) & 14.63 (0.8) & 10125.97 (163.38)\\
\hline
gompertz & exp & -5064.99 (80.41) & 11.45 (0.45) & 10129.99 (160.82)\\
\hline
 & gompertz & -5065.61 (80.44) & 11.66 (0.48) & 10131.22 (160.88)\\
\hline
 & loglogistic & -4970.42 (80.79) & 11.68 (0.34) & 9940.84 (161.59)\\
\hline
 & lognormal & -4730.92 (92.64) & 18.31 (0.95) & 9461.84 (185.29)\\
\hline
 & weibull & -5063.81 (81.74) & 15.45 (0.85) & 10127.61 (163.48)\\
\hline
loglogistic & exp & -5059.86 (80.47) & 11.29 (0.42) & 10119.73 (160.93)\\
\hline
 & gompertz & -5060.37 (80.4) & 11.64 (0.45) & 10120.74 (160.8)\\
\hline
 & loglogistic & -4966.22 (80.75) & 12.77 (0.35) & 9932.44 (161.5)\\
\hline
 & lognormal & -4726.57 (93.17) & 19.43 (0.91) & 9453.13 (186.34)\\
\hline
 & weibull & -5058.17 (81.84) & 14.8 (0.74) & 10116.33 (163.67)\\
\hline
lognormal & exp & -4972.55 (84.58) & 16.35 (0.61) & 9945.09 (169.15)\\
\hline
 & gompertz & -4973.16 (84.69) & 16.5 (0.56) & 9946.32 (169.38)\\
\hline
 & loglogistic & -4877.87 (85.79) & 16.53 (0.5) & 9755.74 (171.59)\\
\hline
 & lognormal & -4638.85 (100.27) & 23.58 (1) & 9277.71 (200.55)\\
\hline
 & weibull & -4970.22 (86.17) & 19.01 (0.89) & 9940.44 (172.34)\\
\hline
weibull & exp & -5063.26 (80.7) & 11.93 (0.46) & 10126.53 (161.4)\\
\hline
 & gompertz & -5064.37 (80.64) & 12.67 (0.52) & 10128.73 (161.28)\\
\hline
 & loglogistic & -4968.74 (81.03) & 12.3 (0.37) & 9937.49 (162.07)\\
\hline
 & lognormal & -4729.78 (93.18) & 19.54 (0.97) & 9459.56 (186.36)\\
\hline
 & weibull & -5061.91 (82.05) & 15.77 (0.85) & 10123.81 (164.11)\\
\hline
\end{tabular}
\begin{tablenotes}%%[341pt]
\textsuperscript{$\dagger$}ELPD: Expected log pointwise predictive density;
\textsuperscript{$\ddagger$}$p_D$: Effective number of parameters
\end{tablenotes}
\end{table*}


\begin{table*}[!ht]
\centering
\caption{WAIC statistics for separate models and all distributions. \label{tab:waic_sep}}
\begin{tabular}{l|l|l|l|l}
\hline
\textbf{OS distn} & \textbf{PFS distn} & \textbf{ELPD\textsuperscript{$\dagger$}} & \textbf{$p_D^{\ddagger}$} & \textbf{WAIC} \\
\hline
exp & exp & -5066.38 (81.4) & 10.46 (0.43) & 10132.76 (162.81)\\
\hline
 & gompertz & -5066.68 (81.46) & 10.38 (0.46) & 10133.37 (162.92)\\
\hline
 & loglogistic & -4971.73 (81.67) & 10.36 (0.28) & 9943.46 (163.34)\\
\hline
 & lognormal & -4732.41 (93.18) & 18.56 (0.99) & 9464.83 (186.36)\\
\hline
 & weibull & -5064.87 (82.86) & 14.39 (0.86) & 10129.74 (165.72)\\
\hline
gompertz & exp & -5066.72 (81.44) & 10.51 (0.45) & 10133.43 (162.89)\\
\hline
 & gompertz & -5066.76 (81.49) & 10.19 (0.44) & 10133.53 (162.97)\\
\hline
 & loglogistic & -4972.24 (81.7) & 10.7 (0.28) & 9944.47 (163.4)\\
\hline
 & lognormal & -4732.23 (93.3) & 18.01 (0.95) & 9464.46 (186.61)\\
\hline
 & weibull & -5064.46 (82.92) & 13.5 (0.78) & 10128.91 (165.83)\\
\hline
loglogistic & exp & -5062.51 (81.89) & 10.79 (0.4) & 10125.02 (163.78)\\
\hline
 & gompertz & -5062.64 (82.01) & 10.26 (0.41) & 10125.27 (164.02)\\
\hline
 & loglogistic & -4968.45 (82.36) & 11.63 (0.28) & 9936.89 (164.72)\\
\hline
 & lognormal & -4728.25 (94.2) & 18.18 (0.92) & 9456.51 (188.4)\\
\hline
 & weibull & -5060.18 (83.31) & 13.79 (0.69) & 10120.37 (166.62)\\
\hline
lognormal & exp & -4973.43 (85.26) & 14.63 (0.55) & 9946.86 (170.53)\\
\hline
 & gompertz & -4973.48 (85.22) & 14.31 (0.51) & 9946.96 (170.44)\\
\hline
 & loglogistic & -4879.07 (86.55) & 15.07 (0.44) & 9758.14 (173.09)\\
\hline
 & lognormal & -4638.43 (100.4) & 21.3 (0.96) & 9276.85 (200.8)\\
\hline
 & weibull & -4972.48 (87.07) & 19.54 (0.91) & 9944.95 (174.13)\\
\hline
weibull & exp & -5064.74 (81.52) & 11.11 (0.45) & 10129.48 (163.04)\\
\hline
 & gompertz & -5065.16 (81.59) & 11.16 (0.44) & 10130.32 (163.18)\\
\hline
 & loglogistic & -4970.64 (81.87) & 11.68 (0.35) & 9941.27 (163.73)\\
\hline
 & lognormal & -4730.93 (93.78) & 19.04 (0.96) & 9461.85 (187.56)\\
\hline
 & weibull & -5063.2 (83.09) & 14.87 (0.83) & 10126.41 (166.17)\\
\hline
\end{tabular}
\begin{tablenotes}%%[341pt]
\textsuperscript{$\dagger$}ELPD: Expected log pointwise predictive density;
\textsuperscript{$\ddagger$}$p_D$: Effective number of parameters
\end{tablenotes}
\end{table*}

% \begin{landscape}
% \begin{sidewaysfigure}[H]
\begin{figure}[hbt!]
\centering
\includegraphics[height=10cm, width=0.9\linewidth]{forest_plot_joint_cf_hier.png}
\caption{\label{fig:cf_forest_all_tx} Hierarchical mixture cure model posterior cure fraction forest plots with 95\% credible intervals for (i) ipilimumab only (ii) nivolumab only and (iii) combination treatment.}
% \end{sidewaysfigure}
\end{figure}
% \end{landscape}

% \begin{landscape}
% \begin{sidewaysfigure}[H]
\begin{figure}[hbt!]
\centering
\includegraphics[height=10cm, width=0.9\linewidth]{forest_plot_joint_all_tx_separate.png}
\caption{\label{fig:cf_forest_all_tx_sep} Separate mixture cure models posterior cure fraction forest plots with 95\% credible intervals for (i) ipilimumab only (ii) nivolumab only and (iii) combination treatment.}
% \end{sidewaysfigure}
\end{figure}
% \end{landscape}

%
\subsection{All data-cuts results}\label{sec:results-data-cut}
We now turn our attention to fitting the mixture cure models to earlier data-cuts in the CheckMate 067 trial data set. 
Figures~\ref{fig:forest_plot_cf_cutpoint_sep} and Figure~\ref{fig:forest_plot_cf_cutpoint_hier} show forest plots of the cure fraction estimates for 12, 30 and 60 months and for the separate and hierarchical models, respectively.
Results are shown for the OS exponential with PFS exponential model and the OS log-Normal with PFS log-Normal model.

We can see that in Figure~\ref{fig:forest_plot_cf_cutpoint_sep} for the exponential model in the OS survival curves for the separate model there is more uncertainty than in the equivalent plot for the hierarchical model in Figure~\ref{fig:forest_plot_cf_cutpoint_hier}.
The log-Normal model OS survival curves for separate and hierarchical models over-estimate the cure fraction at earlier data-cuts and all treatment arms.
For later data-cuts the cure fractions appear to converge from above to the complete data estimates.
% It appears to revert to the background survival at the time of the last observed data point.

Conversely, for the separate models and all treatment arms, at 12 months follow-up the exponential model underestimates the OS cure fraction and approaches the complete data value from below.
This is less clear than for the log-Normal model probably because of the larger estimate uncertainty for the exponential model.
Crucially, these are two clearly different behaviours but we would be ignorant to which is correct (if any) until later on in the trial.
For OS in the hierarchical model the cure fraction estimates appear to be accurate and more certain even at 12 months for all treatment arms.
The posterior is more stable about the complete data cure fraction for all considered data-cuts.


Figures~\ref{fig:S_cutpoint_12mo_sep} and \ref{fig:S_cutpoint_12mo_hier} show the survival curves for the data-cut with 12 months of follow-up data for the the exponential and log-Normal models and for the separate and hierarchical models respectively.
Equivalent Figures for 30 months data-cut are given in the Appendix.

%% restricted mean survival times
Comparing the uncured RMSTs for various models,
the hierarchical exponential model gives for OS 20.6 (18.4, 23.1) and PFS 6.72 (6.15, 7.34) months.
For the separate model, OS is 22.3 (18.5, 26.9) and PFS is 5.68 (4.9, 6.45) months.
For the log-Normal hierarchical model the RMST for OS end-point is 6.6 (6.17, 7.13) and PFS is 3.98 (3.84, 4.12) months.
Finally, the separate model gives 6.59 (6.18, 7.07) months for OS and 3.98 (3.85, 4.1) months for PFS.


\begin{figure}[!ht]
\centering
\includegraphics[height=10cm, width=0.6\linewidth]{forest_plot_cf_sep_cpt.png}
\caption{\label{fig:forest_plot_cf_cutpoint_sep} Posterior cure fraction forest plot with 95\% credible intervals for study data with cutpoint censoring at 12 months, 30 months and the complete data set using the separate mixture cure models.}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[height=10cm, width=0.6\linewidth]{forest_plot_cf_hier_cpt.png}
\caption{\label{fig:forest_plot_cf_cutpoint_hier} Posterior cure fraction forest plot with 95\% credible intervals for study data with cutpoint censoring at 12 months, 30 months and the complete data set using the hierarchical mixture cure model.}
\end{figure}

\note[NGreen]{show complete data with dotted line?}

\begin{figure}[!ht]
\centering
\includegraphics[height=10cm, width=0.6\linewidth]{plot_S_grid_cf_sep_cpt_12m.png}
\caption{\label{fig:S_cutpoint_12mo_sep} Separate mixture cure models posterior survival curves with 95\% credible intervals for (I) PFS and OS exponential uncured survival curves and (II) PFS and OS log-Normal uncured survival curves and censored times at a 12 month cutpoint. The black lines show the observed data Kaplan-Meier curves.}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[height=10cm, width=0.6\linewidth]{plot_S_grid_cf_hier_cpt_12m.png}
\caption{\label{fig:S_cutpoint_12mo_hier} Hierarchical mixture cure model posterior survival curves with 95\% credible intervals for (I) PFS and OS exponential uncured survival curves and (II) PFS and OS log-Normal uncured survival curves and censored times at a 12 month cutpoint. The black lines show the observed data Kaplan-Meier curves.}
\end{figure}

% % CrI ratios
% The ratio of the CrIs of the separate and hierarchical cure fractions didn't show any significant difference for the complete data set.
% For the cut-point samples...

% table?


%
\section{Discussion}\label{sec:discussion}
We have presented a Bayesian hierarchical mixture cure model to obtain complete survival curves which exhibit plateau behaviour. These curves can then be used in HTA to inform functions of patient lifetime.
We have demonstrated the novel method using the CheckMate 067 trial data set for two end-points and at different artificial data-cuts.
The hierarchical model was compared with the separate model analogue and has been shown to be superior as well as both principled and applicable to situations where trials include multiple treatment arms and end-points.

One of the benefit of adopting a hierarchical Bayesian approach is robustness to smaller sample sizes due to providing prior information and borrowing of strength between data for different end-points.
This results in the stabilisation of the cure fraction estimates.
It may be that there is excessive borrowing of information between cure fractions when the end-points are distinctly different.
In our example, this was not necessary since there are only two end-points but for a larger number this may be appropriate.
Partial-exchangeability can be used instead in this case \cite{Neuenschwander2016}.

% choice of priors
In comparison to some previous frequentist approaches, our framework is able to include contextual information about the parameters of the model via the prior distributions.
Incorporating sensible information, both in the form of external data sources or elicited from experts can
stabilise the inference on the cure fraction and restrict/constrain its values via the prior distributions.
For the analysis presented in this paper we chose uninformative priors.
This allows the data to dominate the posterior even if the dataset is relatively small.
In practice there may be additional information from clinical experience or previous data that can better inform the prior selection.
The priors can be specified on the natural scale to aid elicitation and interpretation.
For example, we may have clinical knowledge that a drug treatment could generate a cure fraction greater than, say, 30\%.
If a (cancer) patient enters the study at 60 years old then there is a high degree of certainty that they will not live for, say, over 40 years.
In the case of sparse data e.g. when there is a large amount of missing data perhaps due to right censoring, then 'regularising' the inference based on available prior information could make a significant and important difference. In particular, the method of blending curves is a recent, straightforward option for how to constrain survival \citep{Che2022}. 
How to elicit this prior information in practice may not be simple and a formal protocol should be adopted \cite{OHagan2019}.

Health care regulators, such as the European Medicines Agency (EMA) and U.S. Food and Drug Administration (FDA), may value the fact that a hierarchical model can embed some form of prior knowledge to account for scepticism.
This will prevent the cure rates to be taken at face value, particularly with limited data.
The hierarchical model seems to give a more precise estimate of the cure rate, even with earlier data-cuts (especially for the Exponential model).
The hierarchical model is more aligned, which means possibly you have more reliable estimates early on, which is a good argument to complement modelling based on earlier cuts.
% Earlier cuts can lead to quicker introduction in the market and reimbursement decisions.

% data
Future work should test the proposed hierarchical MCM on a variety of data sets and at data-cuts reflecting their actual trial protocols.
The modelling framework is generalisable from two end-points in our example to any number in principle.
For example, previous related frequentist analyses considered clusters of hospitals and recurrent events per individual \citep{Lai2008, Lai2009}.
Further work could investigate the benefit to including additional end-point data even if it does not clearly demonstrate plateauing behaviour.
The survival curve used in the model for the general population background statistically 'cured' survival can be refined to be appropriate to specific cohort characteristics. For instance, long term survival of clinically identified complete responders (CR) could be used to bridge the gap between statistical cure and clinical cure/functional cure. The shorter-term CR individual-level survival data can be combined with longer-term external data such as from WHO life tables as in the current analysis (see \citep{Jackson2017} for potential approaches).

% optimal stopping
Another way to think about the cut-point data is to think about what is the minimum follow-up time should we choose to halt the trial and end the data collection which would maximise some expected overall utility.
% RSS conference talk ref? Anna?
That is, put another way, what is the optimal stopping time $\tau^*$ for the total utility $V$?
$$
\mathbb{E} V_{\tau^*} = \sup_{\tau} \mathbb{E} V_{\tau}
$$
The stopping utility should incorporate a measure of the survival extrapolation robustness and may include benefits such as smaller costs, freed-up time from the trial for patients and those running the study, quicker time to market for a drug, avoidance of side-effects etc.
The utility would also depend on estimating 'correct' parameters values from the available data i.e. that they are within some acceptable threshold of the true values.
This could be applied directly on the parameters of interest or an order statistics for which drug is deemed the preferable.

This may be framed in terms of value of information (VoI) \citep{Heath2017}.
For example, in the case given above, what is the additional value of obtaining further data after 12 and 30 months.
In practice, deriving a set of heuristics may be better than formalising a general rule.
A discrete set of cut-point may be used, similar to our artificial selection of rounded times 12 and 30 months, rather than considering the whole real line.

As well as during a study, the hierarchical MCM could be used in advance of a study to inform trial design and optimal follow-up time to support the choice of data-cuts used in practice. Smaller sample sizes and shorter duration may provide equivalent power given the exploitation of additional model structure.

% implications for HTA
There are several implications for HTA by using the hierarchical mixture cure model presented here.
In a cost-effectiveness analysis unstable estimates over time would give different estimates of benefit and thus cost-effectiveness statistics and potentially differing optimal decisions.
Lee~(2019)\cite{Lee2019} performed a cost-effectiveness analysis of using nivolumab with ipilimumab vs ipilimumab using the CheckMate 067 trial data, and a partitioned survival model and Markov state-transition model. Lifetime costs and benefits were estimated.
Results were obtained using 18-month (when OS data were unavailable) and 36-month (OS available) CheckMate 067 data-cuts. They showed that the model using OS data generated more than 1 additional quality-adjusted life-year (QALY) across both treatment arms compared to the model without OS data.
Using our approach, we have shown that reliable estimates of complete survival curves can be obtained even for early data-cuts. These can be used to estimate lifetime horizon benefits in instances where perhaps previously estimates were not available.
In our example, the OS cure fraction is accurate and stable at 12 months for the hierarchical mixture cure model with exponential distributions for the OS and PFS uncured survival models.

Additional benefits are potential early stopping (cheaper, improved health, quicker drugs to market for producers and patients benefit),
smaller trials,

The key conclusion of this paper is that data are available for better more efficient estimation of the outcomes of trials. Standard models are generally not up to the task but we have demonstrated a novel model which can achieve this.

\note[NGreen]{how should the complete responders be included in the main model? If they enter via the background adjustment why double-count them?}
\note[NGreen]{model averaging using all distributions and weights from LOO/WAIC?}
\note[NGreen]{extensions of the implementation could be to generalise to have different distributions for each treatment in a single model fit, rather than at the moment where they are assumed to be the same for all treatments.}

% % previous methodology work
% In previous work, a multilevel frailty cure fraction model for the latent variable formulation was considered by \cite{Tawiah2020}.
% A related generalisation by \cite{Balogun2020} consider a single end-point but multiple co-infections with different cure fractions, similar to how we have different cure fractions for each treatment.

% In terms of an end-point of interest and a surrogate end-point Papanikos~(2020) \cite{Papanikos2020} modelled their relationship using a Bivariate Normal distribution.
% We could have done something similar for the OS and PFS event times, especially since the latter is a lower bound for the former.

%\backmatter

\section*{Acknowledgements}
This is acknowledgement text.

\subsection*{Author contributions}

This is an author contribution text.

\subsection*{Financial disclosure}

None reported.

\subsection*{Conflict of interest}

The authors declare no potential conflict of interests.


% \section*{Supporting information}

% The following supporting information is available as part of the online article:

\newpage

% Stan?
% \begin{lstlisting}[caption = {Descriptive Caption Text}, label=DescriptiveLabel]
% for i:=maxint to 0 do
% \end{lstlisting}

% %\nocite{*}% Show all bib entries - both cited and uncited; comment this line for only cited entries
\bibliography{bibliography}

% \clearpage

% \section*{Author Biography}

% \begin{biography}{\includegraphics[width=66pt,height=86pt,draft]{empty}}{\textbf{Author Name.} This is sample author is sample author biography text.}
% \end{biography}

\end{document}

%%**journal table template**
% \begin{center}
% \begin{table*}[t]%
% \caption{This is sample table caption.\label{tab1}}
% \centering
% \begin{tabular*}{500pt}{@{\extracolsep\fill}lccD{.}{.}{3}c@{\extracolsep\fill}}
% \toprule
% &\multicolumn{2}{@{}c@{}}{\textbf{Spanned heading\tnote{1}}} &lticolumn{2}{@{}c@{}}{\textbf{Spanned heading\tnote{2}}} \\\cmidrule{2-3}\cmidrule{4-5}
% \textbf{col1 head} & \textbf{col2 head}  & \textbf{col3 head}  &lticolumn{1}{@{}l@{}}{\textbf{col4 head}}  & \textbf{col5 head}   \\
% \midrule
% col1 text & col2 text  & col3 text  & 12.34  & col5 text\tnote{1}   \\
% col1 text & col2 text  & col3 text  & 1.62  & col5 text\tnote{2}   \\
% col1 text & col2 text  & col3 text  & 51.809  & col5 text   \\
% \bottomrule
% \end{tabular*}
% \begin{tablenotes}%%[341pt]
% \item Source: Example for table source text.
% \item[1] Example for a first table footnote.
% \item[2] Example for a second table footnote.
% \end{tablenotes}
% \end{table*}
% \end{center}
